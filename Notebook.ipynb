{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## This notebook is an assessment test for Machine Learning Engineer position at Startup Crafters, basic skill test.\n\n# **PROBLEM STATEMENT**\n#### Aim: The task is to train a neural network model on the provided training data and reach the maximum accuracy you can achieve. Dataset consists of 2400 total images distributed across the training, validation and test set.\n#### The dataset consists of three folders training (1,440 images), validation (480 images) and testing dataset (480 images).\n#### The images are divided into six classes, \n   1. Bicycle\n   2. Boat\n   3. Cat\n   4. Motorbike\n   5. People\n   6. Table\n\n# **DATA PREPROCESSING**\n#### 1. Importing Libraries","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"from keras.layers import MaxPool2D,Flatten,Dense,Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications import EfficientNetB3\nfrom tensorflow.keras.preprocessing import image\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.callbacks import EarlyStopping\nfrom keras.preprocessing.image import *\nfrom keras.utils import np_utils\nimport matplotlib.pylab as plt\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport os\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 2. Data fetching\n","metadata":{}},{"cell_type":"code","source":"os.chdir(\"../input/multiclassification-dataset-6classes/AI test\") #setting working directory\n#taking file path and labels\ntrain = ImageDataGenerator(rescale=1/255)\nval = ImageDataGenerator(rescale=1/255)\ntest = ImageDataGenerator(rescale=1/255)\n\ntrain_dataset = train.flow_from_directory('../input/multiclassification-dataset-6classes/AI test/Training',target_size=(300,300),batch_size=1) #Fetching training images\nvalidation_dataset = val.flow_from_directory('validation',target_size=(300,300),batch_size=1) #Fetching validation images\ntesting_dataset = test.flow_from_directory('testing',target_size=(300,300)) #Fetching testing data\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3. Image Showing using CV2","metadata":{}},{"cell_type":"code","source":"#Image showing\ntrain_labels= train_dataset.classes\nclasses = train_dataset.class_indices\nimg = train_dataset[0][0] #Change the index to see different image in training set\nimg = np.reshape(img,(300,300,3))\ncv2.imshow(\"image_instance\",img)\ncv2.waitKey(0) # wait for ay key to exit window\ncv2.destroyAllWindows() # close all windows","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###### Herein, In this step, Bicycle is coded as 0, Boat as 1, Cat as 2, Motorbike as 3, People as 4 and Table as 5.","metadata":{}},{"cell_type":"markdown","source":"# **MODEL DEVELOPMENT**\n#### 1. Model-1 (Simplest deep CNN model)","metadata":{}},{"cell_type":"code","source":"\n#Model-1\nmodel = Sequential()\nmodel.add(Conv2D(128,(3,3),activation='swish',input_shape=(300,300,3)))\nmodel.add(MaxPool2D(2,2))\nmodel.add(Conv2D(64,(3,3),activation='swish'))\nmodel.add(MaxPool2D(2,2))\nmodel.add(Conv2D(32,(3,3),activation='swish'))\nmodel.add(MaxPool2D(2,2))\nmodel.add(Conv2D(16,(3,3),activation='swish'))\nmodel.add(MaxPool2D(2,2))\nmodel.add(Flatten())\nmodel.add(Dense(264,activation='swish'))\nmodel.add(Dense(6,activation='softmax'))\nmodel.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])\nepochs=20\nmodel.summary() ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### The accuracy on this model is ~0.30 on validation dataset, training set its 0.97 in 100 epochs. ","metadata":{}},{"cell_type":"markdown","source":"#### 2. Model-2 (Pre-trained InceptionV3 using imagenet features)\n","metadata":{}},{"cell_type":"code","source":"transfered=InceptionV3(include_top=False,weights='imagenet',input_tensor=None,input_shape=(None,None,3),pooling='avg',classes=6)\nmodel=Sequential()\nmodel.add((InputLayer(None,None,3)))\nmodel.add(transfered)\nmodel.add(Dropout(0.1))\nmodel.add(Dense(6,activation='softmax'))\ntransfered.trainable=False\nmodel.compile(optimizer=optim,loss='categorical_crossentropy',metrics=['acc'])\nepochs=10\nmodel.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### The accuracy on this model is ~0.3975 on validation dataset and 0.98 on training dataset in 100 epochs.","metadata":{}},{"cell_type":"markdown","source":"#### 3. Model-3 (Pre-trained EfficientNetB3 using imagenet features)\n","metadata":{}},{"cell_type":"code","source":"transfered=EfficientNetB3(include_top=False,weights='imagenet',input_shape=(None,None,3),classes=6)\nmodel=Sequential()\nmodel.add((InputLayer(300,300)))\nmodel.add(transfered)\nmodel.add(Dropout(0.2))\nmodel.add(Dense(6,activation='softmax'))\ntransfered.trainable=False\nmodel.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])\nbatch_size=10\nepochs=10\nmodel.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### The accuracy on this model is ~0.32 on validation dataset and 0.70 on training dataset in 100 epochs.","metadata":{}},{"cell_type":"markdown","source":"## **MODEL FITTING**","metadata":{}},{"cell_type":"code","source":"model_fit = model.fit(train_dataset,epochs=epochs,validation_data=validation_dataset,callbacks=[ModelCheckpoint(filepath='./weights.hdf5',monitor='val_acc',verbose=1,save_best_only=True)])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **MODEL PREDICTION**","metadata":{}},{"cell_type":"code","source":"#Model Prediction\nimages = []\nfor img in os.listdir('Testing'):\n    img = os.path.join('Testing', img)\n    img = image.load_img(img, target_size=(300, 300))\n    img = image.img_to_array(img)\n    img = np.expand_dims(img, axis=0)\n    images.append(img)\n\n# stack up images list to pass for prediction\nimages = np.vstack(images)\nclasses_test = model.predict_classes(images, batch_size=10)\nprint(classes_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Notes\ni. I have used three models for this dataset and received respective accuracy, I see inceptionv3 is working better in these cases. \n\nii. Due to time limit, i used few epochs with grid search hyperparamterization but can be increase using hyperparametrization techniques and ensembles.\n\niii. I used my laptop GPU for training and tuning, GTX 1050 Ti MSI GL63.","metadata":{}}]}